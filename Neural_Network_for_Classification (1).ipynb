{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytlEcZjWJXeO"
      },
      "source": [
        "#classifying clothing items using ANN"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usGewigzJM2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c48106d-357d-4384-bb56-5bfe52530f47"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgCJSvtbJjWK"
      },
      "source": [
        "###Dataset\n",
        "For this tutorial we will use the MNIST Fashion Dataset. This is a dataset that is included in keras.\n",
        "\n",
        "This dataset includes 60,000 images for training and 10,000 images for validation/testing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoTVsXF1JpH9"
      },
      "source": [
        "#loading from keras built-in dataset\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist  # load dataset\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()  # split into testing and training"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II34AsVVJpo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b929fcd2-60f4-4597-cd8d-e059133b6e4c"
      },
      "source": [
        "#let's see the shape of data frame\n",
        "\n",
        "train_images.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kofv_Ydojpgi"
      },
      "source": [],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOWw6rCcKCIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c60541-5cb7-4348-c958-773f6654c5b9"
      },
      "source": [
        "#we can see one image\n",
        "\n",
        "train_images[1]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,  41, 188, 103,\n",
              "         54,  48,  43,  87, 168, 133,  16,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   1,   0,   0,   0,  49, 136, 219, 216, 228, 236,\n",
              "        255, 255, 255, 255, 217, 215, 254, 231, 160,  45,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  14, 176, 222, 224, 212, 203, 198, 196,\n",
              "        200, 215, 204, 202, 201, 201, 201, 209, 218, 224, 164,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 188, 219, 200, 198, 202, 198, 199, 199,\n",
              "        201, 196, 198, 198, 200, 200, 200, 200, 201, 200, 225,  41,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  51, 219, 199, 203, 203, 212, 238, 248, 250,\n",
              "        245, 249, 246, 247, 252, 248, 235, 207, 203, 203, 222, 140,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 116, 226, 206, 204, 207, 204, 101,  75,  47,\n",
              "         73,  48,  50,  45,  51,  63, 113, 222, 202, 206, 220, 224,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 200, 222, 209, 203, 215, 200,   0,  70,  98,\n",
              "          0, 103,  59,  68,  71,  49,   0, 219, 206, 214, 210, 250,  38,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 247, 218, 212, 210, 215, 214,   0, 254, 243,\n",
              "        139, 255, 174, 251, 255, 205,   0, 215, 217, 214, 208, 220,  95,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,  45, 226, 214, 214, 215, 224, 205,   0,  42,  35,\n",
              "         60,  16,  17,  12,  13,  70,   0, 189, 216, 212, 206, 212, 156,\n",
              "          0,   0],\n",
              "       [  0,   0,   0, 164, 235, 214, 211, 220, 216, 201,  52,  71,  89,\n",
              "         94,  83,  78,  70,  76,  92,  87, 206, 207, 222, 213, 219, 208,\n",
              "          0,   0],\n",
              "       [  0,   0,   0, 106, 187, 223, 237, 248, 211, 198, 252, 250, 248,\n",
              "        245, 248, 252, 253, 250, 252, 239, 201, 212, 225, 215, 193, 113,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  17,  54, 159, 222, 193, 208, 192, 197,\n",
              "        200, 200, 200, 200, 201, 203, 195, 210, 165,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  47, 225, 192, 214, 203, 206,\n",
              "        204, 204, 205, 206, 204, 212, 197, 218, 107,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   1,   6,   0,  46, 212, 195, 212, 202, 206,\n",
              "        205, 204, 205, 206, 204, 212, 200, 218,  91,   0,   3,   1,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,  11, 197, 199, 205, 202, 205,\n",
              "        206, 204, 205, 207, 204, 205, 205, 218,  77,   0,   5,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   3,   0,   2, 191, 198, 201, 205, 206,\n",
              "        205, 205, 206, 209, 206, 199, 209, 219,  74,   0,   5,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   2,   0,   0, 188, 197, 200, 207, 207,\n",
              "        204, 207, 207, 210, 208, 198, 207, 221,  72,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   2,   0,   0, 215, 198, 203, 206, 208,\n",
              "        205, 207, 207, 210, 208, 200, 202, 222,  75,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 212, 198, 209, 206, 209,\n",
              "        206, 208, 207, 211, 206, 205, 198, 221,  80,   0,   3,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 201, 205, 208, 207,\n",
              "        205, 211, 205, 210, 210, 209, 195, 221,  96,   0,   3,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 202, 201, 205, 209, 207,\n",
              "        205, 213, 206, 210, 209, 210, 194, 217, 105,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 204, 205, 208, 207,\n",
              "        205, 215, 207, 210, 208, 211, 193, 213, 115,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 204, 207, 207, 208, 206,\n",
              "        206, 215, 210, 210, 207, 212, 195, 210, 118,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 208, 208, 208, 204,\n",
              "        207, 212, 212, 210, 207, 211, 196, 207, 121,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 210, 207, 208, 206,\n",
              "        209, 213, 212, 211, 207, 210, 197, 207, 124,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 172, 210, 203, 201, 199,\n",
              "        204, 207, 205, 204, 201, 205, 197, 206, 127,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 188, 221, 214, 234, 236,\n",
              "        238, 244, 244, 244, 240, 243, 214, 224, 162,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 139, 146, 130, 135, 135,\n",
              "        137, 125, 124, 125, 121, 119, 114, 130,  76,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Vge-IQKT2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c309332a-18b2-438e-b349-72df6c28c146"
      },
      "source": [
        "#The labels are integer values in range 0-9\n",
        "train_labels[:10]  # let's have a look at the training labels"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyVd0yn2Kkqg"
      },
      "source": [
        "#let's create a list of names that can be seen during predictions for better understanding\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjSiP3TFFYST",
        "outputId": "aba65542-c9ea-4ab5-fa86-781ede53e6d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj3R3ThFK-E2"
      },
      "source": [
        "##Data Preprocessing\n",
        "The last step before creating our model is to *preprocess* our data. This simply means applying some prior transformations to our data before feeding it the model. In this case we will simply scale all our greyscale pixel values (0-255) to be between 0 and 1. We can do this by dividing each value in the training and testing sets by 255.0. We do this because smaller values will make it easier for the model to process our values. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7HGyILFK2xW"
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "relu ={\n",
        "\n",
        "              0, for x < 0\n",
        "              x  for x >=0\n",
        "        }"
      ],
      "metadata": {
        "id": "PZPH08mlDgsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation function\n",
        "\n",
        "\n",
        "(binary classification)\n",
        "1) sigmoid : 0 and 1\n",
        "\n",
        "(multiclass classification)\n",
        "2) Softmax : probabilities for each node in the layer\n",
        "\n",
        "3)  RELU  : gives answer if input is postive"
      ],
      "metadata": {
        "id": "EQg8V0-Ygrfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperas"
      ],
      "metadata": {
        "id": "OFEVQTVzzGHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAZB2hkMLJ4m"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),  # input layer (1)\n",
        "    keras.layers.Dense(16, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation='softmax') # output layer (3)\n",
        "])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-bL-I5w0414"
      },
      "source": [
        "[link text](https://)**Layer 1:** This is our input layer and it will conist of 784 neurons. We use the flatten layer with an input shape of (28,28) to denote that our input should come in in that shape. The flatten means that our layer will reshape the shape (28,28) array into a vector of 784 neurons so that each pixel will be associated with one neuron.\n",
        "\n",
        "**Layer 2:** This is our first and only hidden layer. The *dense* denotes that this layer will be fully connected and each neuron from the previous layer connects to each neuron of this layer. It has 128 neurons and uses the rectify linear unit activation function.\n",
        "\n",
        "**Layer 3:** This is our output later and is also a dense layer. It has 10 neurons that we will look at to determine our models output. Each neuron represnts the probabillity of a given image being one of the 10 different classes. The activation function *softmax* is used on this layer to calculate a probabillity distribution for each class. This means the value of any neuron in this layer will be between 0 and 1, where 1 represents a high probabillity of the image being that class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRRYXqS4OArF"
      },
      "source": [
        "#let's compile the model. More details in the parameters used in compile in coming sessions\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add early stopping\n"
      ],
      "metadata": {
        "id": "Hc-Ihx4tGJ0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.005, patience=10)\n",
        "mc = ModelCheckpoint('best_model.pkl', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "dfsEHKnYGK5K"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU3VIbKLOLnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93e3458-91d1-4064-aa83-2aba395af20d"
      },
      "source": [
        "#Now we can train the model\n",
        "records = model.fit(train_images, \n",
        "          train_labels, \n",
        "          epochs=50, \n",
        "          validation_data=(test_images,test_labels),\n",
        "          callbacks=[es,mc])  # we pass the data, labels and epochs and watch the magic!"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2288 - accuracy: 0.9159"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1875/1875 [==============================] - 6s 3ms/step - loss: 0.2289 - accuracy: 0.9159 - val_loss: 0.4806 - val_accuracy: 0.8610\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2295 - accuracy: 0.9161 - val_loss: 0.4973 - val_accuracy: 0.8526\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2301 - accuracy: 0.9159 - val_loss: 0.4807 - val_accuracy: 0.8590\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2298 - accuracy: 0.9154 - val_loss: 0.4857 - val_accuracy: 0.8569\n",
            "Epoch 5/50\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.2288 - accuracy: 0.9166"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1875/1875 [==============================] - 6s 3ms/step - loss: 0.2288 - accuracy: 0.9166 - val_loss: 0.4819 - val_accuracy: 0.8611\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2307 - accuracy: 0.9156 - val_loss: 0.4801 - val_accuracy: 0.8579\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2283 - accuracy: 0.9162 - val_loss: 0.4887 - val_accuracy: 0.8562\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2289 - accuracy: 0.9161 - val_loss: 0.4855 - val_accuracy: 0.8589\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2278 - accuracy: 0.9162 - val_loss: 0.4924 - val_accuracy: 0.8594\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2273 - accuracy: 0.9163 - val_loss: 0.4845 - val_accuracy: 0.8593\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2281 - accuracy: 0.9168 - val_loss: 0.4853 - val_accuracy: 0.8572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame( records.history   ,columns=list(records.history.keys()) )\n",
        "\n",
        "results_df.sort_values(by=\"val_accuracy\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "MmiVBtY0Ioot",
        "outputId": "2820d225-04a8-4894-ea22-8325195ab809"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy\n",
              "7   0.230663  0.915067  0.470041        0.8618\n",
              "1   0.233458  0.914317  0.458380        0.8606\n",
              "6   0.231372  0.915183  0.484208        0.8603\n",
              "4   0.232100  0.914633  0.467922        0.8599\n",
              "9   0.229881  0.916033  0.473967        0.8595\n",
              "0   0.233653  0.914450  0.473432        0.8583\n",
              "5   0.230479  0.914767  0.468635        0.8580\n",
              "8   0.232133  0.915033  0.486482        0.8580\n",
              "3   0.232797  0.914217  0.465227        0.8578\n",
              "10  0.230971  0.914733  0.490678        0.8578\n",
              "2   0.233051  0.914617  0.473874        0.8572"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de77ee93-553b-40cb-8fc6-11b8f261a858\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.230663</td>\n",
              "      <td>0.915067</td>\n",
              "      <td>0.470041</td>\n",
              "      <td>0.8618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.233458</td>\n",
              "      <td>0.914317</td>\n",
              "      <td>0.458380</td>\n",
              "      <td>0.8606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.231372</td>\n",
              "      <td>0.915183</td>\n",
              "      <td>0.484208</td>\n",
              "      <td>0.8603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.232100</td>\n",
              "      <td>0.914633</td>\n",
              "      <td>0.467922</td>\n",
              "      <td>0.8599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.229881</td>\n",
              "      <td>0.916033</td>\n",
              "      <td>0.473967</td>\n",
              "      <td>0.8595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.233653</td>\n",
              "      <td>0.914450</td>\n",
              "      <td>0.473432</td>\n",
              "      <td>0.8583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.230479</td>\n",
              "      <td>0.914767</td>\n",
              "      <td>0.468635</td>\n",
              "      <td>0.8580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.232133</td>\n",
              "      <td>0.915033</td>\n",
              "      <td>0.486482</td>\n",
              "      <td>0.8580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.232797</td>\n",
              "      <td>0.914217</td>\n",
              "      <td>0.465227</td>\n",
              "      <td>0.8578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.230971</td>\n",
              "      <td>0.914733</td>\n",
              "      <td>0.490678</td>\n",
              "      <td>0.8578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.233051</td>\n",
              "      <td>0.914617</td>\n",
              "      <td>0.473874</td>\n",
              "      <td>0.8572</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de77ee93-553b-40cb-8fc6-11b8f261a858')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de77ee93-553b-40cb-8fc6-11b8f261a858 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de77ee93-553b-40cb-8fc6-11b8f261a858');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWcQgx4RO7XR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd38bf0d-b0ca-4320-ff19-63079ec55c34"
      },
      "source": [
        "#Now,we should evaluate the performance of our model\n",
        "\n",
        "\n",
        "#use data previously not seen by the model for this step\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1) \n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4117 - accuracy: 0.8618\n",
            "Test accuracy: 0.8618000149726868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5P9gMhnPOxZ"
      },
      "source": [
        "You'll likely notice that the accuracy here is lower than when training the model. This difference is reffered to as **overfitting**.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64S5q9VIPT4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1039baed-c116-4080-b435-1faaaced3f32"
      },
      "source": [
        "#Let's make predictions now\n",
        "\n",
        "predictions = model.predict(test_images) #using test images to verify on case by case basis\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IeykuZbPvQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd72e4d7-ab16-4cac-8271-7c0b20883ef6"
      },
      "source": [
        "predictions[0]\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.4806508e-11, 1.6425098e-15, 1.2045339e-07, 1.9467148e-08,\n",
              "       5.5345528e-10, 6.2770292e-04, 3.9811592e-11, 6.6223545e-03,\n",
              "       3.6839531e-06, 9.9274617e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62i7jS6iPxsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ed26bc-99a2-471c-b276-7ac9be07a2e9"
      },
      "source": [
        "np.argmax(predictions[8898])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJgLyCOxPzhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c8d425-33ba-4a78-d7d4-c28ac9480340"
      },
      "source": [
        "test_labels[8898]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usS4LnxWQ0ld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "813e2b00-fe91-4706-e9f1-c6922c105562"
      },
      "source": [
        "\"\"\"\n",
        "Let's see if this is actually what is being predicted!\n",
        "\"\"\"\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(test_images[876])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAD8CAYAAADJwUnTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbXklEQVR4nO3dfZBc1Xnn8e9PMyMNEnoDgSQLATJoCcJgAQpg4xccbEeQFOA4yyKbLE5I5EpZKTt2tsKSlE2RzRbJxvayKUIyDgRw2RAFY1sba6MAxmGJDZbAGCRYjCwLIyEhhIQQL5Jmep79o1u45+We2zPdM32v9PtUdWn6PvfcPtMzeube0889RxGBmVmZTGh3B8zMRsqJy8xKx4nLzErHicvMSseJy8xKx4nLzErHicvMxoykWyXtkLQ+Iy5J/0vSRklPSDqrkeM6cZnZWLoNWJqIXwQsrD2WAzc3clAnLjMbMxHxILArsculwB1R9TAwQ9LcvON2tqqDjZioSdHNlPF8SbPDyj5e50DsVzPH+NUPTImXd1Ua2vfRJ/ZvAPbVbeqJiJ4RvNw84Pm651tq27alGjWVuCQtBW4EOoC/j4gbUvt3M4VzdWEzL2lmCY/E/U0fY+euCo+sOa6hfbvm/nRfRCxp+kVHaNSJS1IHcBPwIapZcq2kVRHxVKs6Z2btEFSif7xebCswv+75cbVtSc2McZ0DbIyITRFxALiL6vWqmZVYAP1EQ48WWAX859qni+cBeyIieZkIzV0qDndteu7gnSQtp/ppAd1MbuLlzGy89NOaMy5JdwIXALMkbQG+AHQBRMTfAquBi4GNwBvAbzdy3DEfnK8N1PUATNNRnkPHrOCCoLdFl4oRsSwnHsCnRnrcZhLXqK5NzazYAqi05jJwzDQzxrUWWChpgaSJwBVUr1fNrOTGcYxrVEZ9xhURfZJWAGuolkPcGhEbWtYzM2uLACoFnxm5qTGuiFhNdXDNzA4h41YMMUrjWjlvZsUXROHHuJy4zGyACOgtdt5y4jKzwUSFpm53HHNOXGY2QAD9PuMys7LxGZeZlUq1ANWJy8xKJIDeKPYco05cZjZAICoFnxzZicvMhugPXyqaWYl4jMvMSkhUPMZlZmVSnQHVicvMSiRCHIiOdncjyYnrcKecsYyCT28yWupM/+pHX18y3jH72GR859KTkvGZt/8gO1iAn0m/x7jMrEyqg/O+VDSzUvHgvJmVjAfnzayUKi5ANbMyCURvFDs1FLt3ZjbuPDhvZqUTyJeKVnCHaJ1WnmbruJ77nZOT8WnvezEZ7/jmtMxY5dVXk22TfU93u2EenDezUonA5RBmVi7VwXnf8mNmJePBeTMrlUCeSNDMysdnXGZWKtV1FZ24zKxUvJK1HebUNTERy6mlOnAgHc+ptUrp379/1G0BTrxtUzL+zOlzkvHp39qXHfyVdB0XHYlP/PqaTzjV5ckO4U8VJW0G9gIVoC8ilrSiU2bWPhEq/KViK3r3gYhY7KRlduioxISGHo2QtFTSM5I2SrpmmPjxkh6Q9CNJT0i6OO+YxU6rZjbuqvNxqaFHHkkdwE3ARcAiYJmkRYN2+1NgZUScCVwB/E3ecZtNXAH8q6RHJS0fbgdJyyWtk7Sul+bGFcxsPKiVZ1znABsjYlNEHADuAi4dtE8AB2/enA68kHfQZgfn3xMRWyUdC9wr6f9FxIMDehTRA/QATNNRh+cdvWYlUi2HaHiQf5akdXXPe2r/5w+aBzxf93wLcO6gY1xH9QToD4ApwAfzXrSpxBURW2v/7pD0TarZ9cF0KzMrshHeq7izBePby4DbIuKLkt4FfFXSOyKiP6vBqC8VJU2RNPXg18CHgfWjPZ6ZFUc/Exp6NGArML/u+XG1bfWuBlYCRMQPgG5gVuqgzZxxzQa+qeoacJ3A1yPiX5o4nmUpwDp7oxW92bVYqdiYa/I969u2PRk/6WPp+Lt+nP29f5/s2jeASNWgteB3oTqtTcsKUNcCCyUtoJqwrgA+NmifnwMXArdJOpVq4nopddBRJ66I2AS8c7Ttzay4WnWTdUT0SVoBrAE6gFsjYoOk64F1EbEK+BzwFUl/SHWI7RMR6QzsynkzG6A6O0TrKqUiYjWwetC2z9d9/RRw/kiO6cRlZgNUb/kpdomnE5eZDVL8W36cuMxsiEaq4tvJicvMBmjxp4pjwonrcDehyelL+ivJ8O6r3jXqQ8+8/Qejbttu2z/97mT8nZPvyIx9n/TSZ+PBl4pmViqec97MSieAPp9xmVnZ+FLRzMolfKloZiVzcCLBInPiMrMhfMZlZqUywokE28KJ6zCnCelf0GaWAAP46B/dlxn7+PQfJdvesOLCZPw7T56ejJ97SvYSYvOP2J1sO73zzWS8S+n6tbldK5Pxe3aelYjmLE82xgLR1+/BeTMrGY9xmVm5hC8VzaxkPMZlZqXkxGVmpRKIigfnzaxsPDhvZqUSHpy3wlNzlwQTzvilZPyU7n/OjK189Yxk23Om/jQZ/7MPPZCMv9SfvVDMZKWX8ZqYsyTcS5X0+3b3nrOT8edfm5n92m2u4wIIJy4zKxffZG1mJeQzLjMrlQio9DtxmVnJ+FNFMyuVwJeKZlY6Hpw3sxKKdLVI2zlxHe6iv6nm2997VDI+p2NPZmwTxybbPvb6icn4lAkHkvHtfdMzYx2kv+/JE/Yn43M6s78vgNcqk5LxFSdk16D18PZk2/FQ9EvF3OpDSbdK2iFpfd22oyTdK+nZ2r/Z1XRmVirVTxUnNPRol0Ze+TZg6aBt1wD3R8RC4P7aczM7REQ09miX3MQVEQ8CuwZtvhS4vfb17cBlre2WmbVThBp6tMtox7hmR8S22tfbgdlZO0paDiwH6GbyKF/OzMZL0N6k1IimL1IjIqiWfmTFeyJiSUQs6SI9YGlmxRANPtpltInrRUlzAWr/7mhdl8ysrQKiXw09GiFpqaRnJG2UNOx4uKTLJT0laYOkr+cdc7SJaxVwVe3rq4Bvj/I4ZlZArRrjktQB3ARcBCwClklaNGifhcB/Bc6PiNOAz+QdN3eMS9KdwAXALElbgC8ANwArJV0NPAdcnvsd2OiN4cc3za6bOOs3nk/GD9CRGdu6f0ay7bxJ6bUPT5+0LRlPOaYzPedVb2T3G+DEnDqu296ckYy/ckSxx3tb+Ct3DrAxIjYBSLqL6od7T9Xt83vATRGxu/rakXsFl5u4ImJZRii9WqeZldII71WcJWld3fOeiOipez4PqP/rtgU4d9Ax/gOApH8HOoDrIuJfUi/qynkzGyiAxhPXzohY0uQrdgILqV7ZHQc8KOn0iHglq0Gxl/Iws7ZoYQHqVmB+3fPjatvqbQFWRURvRPwM+AnVRJbJicvMBmnsE8UGP1VcCyyUtEDSROAKqh/u1fsW1bMtJM2ieum4KXVQJy4zG6pFhVwR0QesANYATwMrI2KDpOslXVLbbQ3wsqSngAeA/xIRL6eO6zEuMxsoWjs7RESsBlYP2vb5uq8D+Gzt0RAnrkOcJqXvVoj96elbJnR3J+O3LLwzGb/vjewpWqZ17ku2nZwzbc0b/elf3xkdr2fGutWbbNsf6YuRSs7Uxp0TKsl4qhxjwtTk8A79e/cm4y3h+bjMrHyKfa+iE5eZDdXc/JJjzonLzAYaWR1XWzhxmdkQnnPezMrHicvMSseXimZWNvIZV0ko5y9M0S/6M+TVaeV59r8tTsZ7475kvJKoh+pQ+qOrN/onJuN5Uq/dbJ1Wb077N/rSff/lSdkzt/zdMUcn2455HVcIGpwksF2cuMxsqIL/nXbiMrOhnLjMrHScuMysVFyAamZl5E8Vzax8nLjMrGx8xlUWRa7Tyqkx08TsmqG8Oq7+9yxOxm+87LZkfOWrZybjeyvZ83m9WelKtl14xIvJeF6tVapOLK9t3nxdee335XxvexNjSC+9d26y7cxNm5PxlvAYl5mVSoPTMreTE5eZDeXEZWZlk3M3Vts5cZnZUD7jMrMyUfhTRTMrI3+qaGal4zMuy6PO9I8h+vrS8UStls4+Ldl26n/fmox/d8+iZHxX75RkvLe/IzM2o+vNZNsupdcmzJ8zK/t9TcUA5nRkr3sIcNSE9M/kqEnZazoCbO6dkRl79ddeS7adeXsy3BJFv1RMz4YGSLpV0g5J6+u2XSdpq6THa4+Lx7abZjZuovqpYiOPdslNXMBtwNJhtn85IhbXHquHiZtZWUWDjzbJTVwR8SCwaxz6YmZFUfbElbBC0hO1S8mZWTtJWi5pnaR1vTQ3/7mZjY+DJRF5j3YZbeK6GTgJWAxsA76YtWNE9ETEkohY0sWkUb6cmdkvjCpxRcSLEVGJiH7gK8A5re2WmbXVoXipKKl+3o2PAOuz9jWzkinBp4q5dVyS7gQuAGZJ2gJ8AbhA0mKqOXcz8Mmx62Lx5dVhofTfh+g90NTrb//0uzNj0y/elmy76YX03E9bps5IxifkDHScdcyWzNi0znQd1zGd6Vqq+R3pMdPeyK4hm9PxRrLtvkRbgPveeHsy/lpvelhk9Z53ZsZ++9SHk22/S7p2riUKXseVm7giYtkwm28Zg76YWQGI4hegunLezIYqeOJqphzCzA5FDZZCNHpWJmmppGckbZR0TWK/j0oKSUvyjunEZWZD9Tf4yCGpA7gJuAhYBCyTNOQGWElTgU8DjzTSPScuMxuihWdc5wAbI2JTRBwA7gIuHWa/PwP+AtjXyEGduMxsqMbruGYdvDOm9lg+6EjzgOfrnm+pbXuLpLOA+RHxnUa7V6jB+dzpXfoTKb4/PQXKWMqbdia3/buyPxoH2LQi/fdlyg+zY0d+NnvpMoDeT2UvHwbwtrnpJcKOn5K+jfWUyduzXzun5GB734xk/MmcJcTW75ufGUstmwawu29yMp7n6Enpcosnd78tM7Zo3gvJth2nLs6MadNDybYNGVlx6c6IyB2TyiJpAvAl4BMjaVeoxGVmxdDCcoitQP1fkONq2w6aCrwD+J6q64fOAVZJuiQi1mUd1InLzIZqXeJaCyyUtIBqwroC+NhbLxOxB5h18Lmk7wF/lEpa4DEuMxtGq275iYg+YAWwBngaWBkRGyRdL+mS0fbPZ1xmNlCLb6CuTTS6etC2z2fse0Ejx3TiMrMBVHsUmROXmQ1V8Ft+nLjMbAjfZF1PQl3ZdUXNTO/SMTNz9mgAKrt3j/rYeTrnH5eMb7r6+GR8/8z0KOfCK9N3QUyYlD2FyrPXn5lse/7ip5PxJdM3J+PHdO5NxrsTtVYvV45Mtv35/qObih/Vmb1E2KlHpJdlm9eZ/n3pVrp2b3tlWjJ+Z+W8zNjEnGO/fnL273r/1nRtXMOcuMysVKK9kwQ2wonLzIbyGZeZlY3HuMysfJy4zKxsfMZlZuUSNDRJYDs5cZnZAF4sY7CIZK1W7wfPTjZ/6czseqUpL6T/ROw9Pn0/+ZtvS8/nFZOyj6996WOftDI9N1PX+p8l4xv/PLvmB+C9v/JkZuzs7vT8TFM70hNOdin9vuzqS9diTe/IrqXaUzki2TZPqk4LoJK4ceXR1xck236/f2EyvnN/+vvuj/RNM50Tst/XdXvTfev+zqOZMVXSv2sNc+Iys7JRFDtzOXGZ2UAtnh1iLDhxmdkQHuMys9LxLT9mVj4+4zKzUhnBKtXt4sRlZkOVPXFJmg/cAcym+u30RMSNko4C/hE4EdgMXB4RTU161f0n25Lx8ybvyYw98OAZybazf5iuRzrhnpeT8ejKfqu0b3+y7d7Tj03Ge1em5xI7b+qGZPyp3bMzYz+fmD72iUem10U8dUr6Z3JKd3oNwNR8XD/dn91vgPV7stceBNj55pRk/MRp2d/bSVNeSrbNq187PnFsgMkT0r8TlcQ6NVdO+0my7UWX/2FmrH/NvyfbNqIMBaiNrPLTB3wuIhYB5wGfkrQIuAa4PyIWAvfXnpvZIUD90dCjXXITV0Rsi4jHal/vpbrE0DzgUuD22m63A5eNUR/NbDzFCB5tMqIxLkknAmcCjwCzI+LgdcR2qpeSZnYIOGTKISQdCXwD+ExEvFpbLhuAiAhp+KtiScuB5QDdTG6ut2Y2Pg6BMS4kdVFNWl+LiHtqm1+UNLcWnwvsGK5tRPRExJKIWNJF9k3SZlYcisYe7ZKbuFQ9tboFeDoivlQXWgVcVfv6KuDbre+emY27ACIae7RJI5eK5wO/BTwp6fHatmuBG4CVkq4GngMuzztQ77FT2P7xd2fG//qEv0m233xgVmbs1y77cbLt65ekz/b2VrqT8UXd2ctZPfTaKcm2D+9+Mxl/dscxyfiWl9IlDVOPzD7+/KmvJNuePXVzMv72icOeSL/l2QNzkvF7X1qUGeuL9N/NK+c+nIx/9Midyfi2Svb78r03Tky2PSnn+36+N7002r7oSsaf25/9u/zQvvTPe/KL2VNDTehtTTIp/RhXRDxE9orcF7a2O2bWbmWo43LlvJkN1ObLwEY4cZnZED7jMrPyceIys7LxGZeZlUsAlWJnLicuMxvCZ1x1una8zpwbf5AZ/91jfz/Z/h3v2ZgZ+/icR5JtU9OrAHR19iXjP37zhMzY9M70klD/ac7aZPyFo2ck491K9603OjJjJ0/anmy7vS/92nfuTC+NNq/7lWT8s/PXZMbely6dY3+kf2a/9N3lyfiVZ/wwM3baEVuSbe/YeX4yfnRXemm0rsTyYwB7+rKXZnv+QLpGbNLm7CmYtD/9u9KwFn6qKGkpcCPQAfx9RNwwKP5Z4HepzkTzEvA7EfFc6pgN3fJjZoeXVt3yI6kDuAm4CFgELKtNi1XvR8CSiDgDuBv4y7zjOnGZ2UCtndbmHGBjRGyKiAPAXVSnxPrFy0U8EBEHL1seBo7LO6jHuMxsAAFqfHB+lqR1dc97IqKn7vk84Pm651uAcxPHuxr4P3kv6sRlZkOMYCXrnRGxpCWvKV0JLAHen7evE5eZDdTa2U23AvPrnh9X2zaApA8CfwK8PyLSE/bjMS4zG6LBKW0aOytbCyyUtEDSROAKqlNivUXSmcDfAZdERHpajhqfcZnZEK2q44qIPkkrgDVUyyFujYgNkq4H1kXEKuB/AEcC/1SbWfnnEXFJ6rjjn7gSWXrBtdk1XgCpypm/ff9Hk22f+/10Xc31Z/7vZPwPZmaXlezpT8+3tSWntGZ+V3pptF2VI5PxVxNzib1SSU+XPaMjXY/UM/97yXiXsmvIAH5j44cyY39880nJttPuTM/HdTI/SsZX/tNZmbGnz08v+ba38rNkPO9nljcf197+7DquX5+SrjH76pJfz4xVdqdft2EtrOOKiNXA6kHbPl/39QdHekyfcZnZQDGiTxXbwonLzIYqdt5y4jKzoUZQDtEWTlxmNpQTl5mVSgBlXyzDzA4vInypaGYl1F/sU65CJS51prsTfdkFURP+LV3Ts+Df0q/9D2TPtwVwx8IPZMZ2vG92su3eD6drpU6buy0ZXzQtPafWgkkvZcZ2VaYk227dn17D70/v/uX0a+fU3lWnVxretESsFY7/j09mxs5b/ZvJtr867+lkfM3LpyXjUzvTd61seX1GZuyOZEuY/tQrmbGON1swH5cvFc2sjHypaGbl48RlZuXiBWHNrGy8yo+ZlZHHuMysfJy4zKxUAugveeKSNJ9qaclsqt9ST0TcKOk64Pf4RaHOtbV5d0YtVafVbpVnN2XGjk7EAI6+JX3sdJUXrCU959Va5uQcISX9ni8gr06rnKZfnL1GJ8DD5M1rlZ6Pa09uD17L3SNLama5BmY9bsChMTjfB3wuIh6TNBV4VNK9tdiXI+Kvxq57ZtYWZU9cEbEN2Fb7eq+kp6kuOWRmh6IAKsUunR/RYhmSTgTOBA6ud79C0hOSbpU07L0jkpZLWidpXS+tOI01s7EVEP2NPdqk4cQl6UjgG8BnIuJV4GbgJGAx1TOyLw7XLiJ6ImJJRCzpYlLzPTazsde6VX7GREOfKkrqopq0vhYR9wBExIt18a8A/zwmPTSz8VWCTxVzz7hUXS/oFuDpiPhS3fa5dbt9BFjf+u6ZWVscAmdc5wO/BTwp6fHatmuBZZIWU83Pm4FPjkH/zKwdDoFPFR8CNEyoqZotMyuoCKik1yFtN1fOm9lQZT/jMrPDkBOXmZVLFP5TRScuMxsoINpYXNoIJy4zG6rgt/w4cZnZQBFenszMSsiD82ZWNuEzLjMrl0NjIkEzO5yU4CZrJy4zGyCAKPgtPyOaSNDMDgPR2okEJS2V9IykjZKuGSY+SdI/1uKP1CYsTXLiMrMhoj8aeuSR1AHcBFwELKI6q8yiQbtdDeyOiJOBLwN/kXdcJy4zG6p1Z1znABsjYlNEHADuAi4dtM+lwO21r+8GLqzNA5hpXMe49rJ7531x93N1m2YBO8ezDyNQ1L4VtV/gvo1WK/t2QrMH2MvuNffF3bMa3L1b0rq65z0R0VP3fB7wfN3zLcC5g47x1j4R0SdpD3A0ifdkXBNXRBxT/1zSuohYMp59aFRR+1bUfoH7NlpF61tELG13H/L4UtHMxtJWYH7d8+Nq24bdR1InMJ2cFXeduMxsLK0FFkpaIGkicAWwatA+q4Cral//JvDdiHQFbLvruHryd2mbovatqP0C9220ity3ptTGrFYAa4AO4NaI2CDpemBdRKyiuhjPVyVtBHZRTW5JyklsZmaF40tFMysdJy4zK522JK68WwDaSdJmSU9KenxQfUo7+nKrpB2S1tdtO0rSvZKerf07s0B9u07S1tp797iki9vUt/mSHpD0lKQNkj5d297W9y7Rr0K8b2Uy7mNctVsAfgJ8iGox2lpgWUQ8Na4dySBpM7AkItperCjpfcBrwB0R8Y7atr8EdkXEDbWkPzMi/rggfbsOeC0i/mq8+zOob3OBuRHxmKSpwKPAZcAnaON7l+jX5RTgfSuTdpxxNXILgAER8SDVT1nq1d8ecTvVX/xxl9G3QoiIbRHxWO3rvcDTVKuz2/reJfplI9SOxDXcLQBF+uEF8K+SHpW0vN2dGcbsiNhW+3o7MLudnRnGCklP1C4l23IZW68208CZwCMU6L0b1C8o2PtWdB6cH+o9EXEW1bvZP1W7JCqkWpFekepZbgZOAhYD24AvtrMzko4EvgF8JiJerY+1870bpl+Fet/KoB2Jq5FbANomIrbW/t0BfJPqpW2RvFgbKzk4ZrKjzf15S0S8GBGVqC7K9xXa+N5J6qKaHL4WEffUNrf9vRuuX0V638qiHYmrkVsA2kLSlNqgKZKmAB8G1qdbjbv62yOuAr7dxr4McDAp1HyENr13tSlRbgGejogv1YXa+t5l9aso71uZtKVyvvZx7//kF7cA/Pm4d2IYkt5O9SwLqrdDfb2dfZN0J3AB1WlPXgS+AHwLWAkcDzwHXB4R4z5IntG3C6he7gSwGfhk3ZjSePbtPcD/BZ4EDk4adS3V8aS2vXeJfi2jAO9bmfiWHzMrHQ/Om1npOHGZWek4cZlZ6ThxmVnpOHGZWek4cZlZ6ThxmVnp/H9wdDAQfoauFAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV4_XZorQUwY"
      },
      "source": [],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF4mYWJyQUsp"
      },
      "source": [],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCrwMRaaQUps"
      },
      "source": [],
      "execution_count": 29,
      "outputs": []
    }
  ]
}